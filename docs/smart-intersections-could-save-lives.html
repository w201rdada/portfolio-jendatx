<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>W201 Portfolio</title>
  <meta name="description" content="W201 Portfolio">
  <meta name="generator" content="bookdown 0.5.9 and GitBook 2.6.7">

  <meta property="og:title" content="W201 Portfolio" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="W201 Portfolio" />
  
  
  

<meta name="author" content="Jennifer Darrouzet">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="brass-knuckles-for-the-information-age.html">
<link rel="next" href="bibliography.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Jennifer Darrouzet</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome!</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#about-the-author"><i class="fa fa-check"></i>About the author</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="brass-knuckles-for-the-information-age.html"><a href="brass-knuckles-for-the-information-age.html"><i class="fa fa-check"></i><b>1</b> Pooook Prose Knuckles</a><ul>
<li class="chapter" data-level="1.1" data-path="brass-knuckles-for-the-information-age.html"><a href="brass-knuckles-for-the-information-age.html#still-chained-to-our-keyboards"><i class="fa fa-check"></i><b>1.1</b> Still Chained to our Keyboards?</a></li>
<li class="chapter" data-level="1.2" data-path="brass-knuckles-for-the-information-age.html"><a href="brass-knuckles-for-the-information-age.html#data-science-to-kick-the-keyboard-habit"><i class="fa fa-check"></i><b>1.2</b> Data Science to Kick the Keyboard Habit</a></li>
<li class="chapter" data-level="1.3" data-path="brass-knuckles-for-the-information-age.html"><a href="brass-knuckles-for-the-information-age.html#the-post-keyboard-era"><i class="fa fa-check"></i><b>1.3</b> The Post-Keyboard Era</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="smart-intersections-could-save-lives.html"><a href="smart-intersections-could-save-lives.html"><i class="fa fa-check"></i><b>2</b> See Around Corners for Traffic Safety</a><ul>
<li class="chapter" data-level="2.1" data-path="smart-intersections-could-save-lives.html"><a href="smart-intersections-could-save-lives.html#smart-self-sensing-intersections-could-save-lives"><i class="fa fa-check"></i><b>2.1</b> Smart, Self-Sensing Intersections Could Save Lives</a></li>
<li class="chapter" data-level="2.2" data-path="smart-intersections-could-save-lives.html"><a href="smart-intersections-could-save-lives.html#the-data-science-of-smart-intersections"><i class="fa fa-check"></i><b>2.2</b> The Data Science of Smart Intersections</a></li>
<li class="chapter" data-level="2.3" data-path="smart-intersections-could-save-lives.html"><a href="smart-intersections-could-save-lives.html#self-driving-cars-to-co-exist-with-smart-intersections"><i class="fa fa-check"></i><b>2.3</b> Self-Driving Cars to Co-Exist with Smart Intersections</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/jendatx" target="blank">GitHub</a></li>
<li><a href="https://www.ischool.berkeley.edu/people/jennifer-darrouzet" target="blank">UC Berkeley</a></li>
<li><a href="https://www.linkedin.com/in/jendarrouzet/" target="blank">LinkedIn</a></li>
        

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">W201 Portfolio</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="smart-intersections-could-save-lives" class="section level1">
<h1><span class="header-section-number">2</span> See Around Corners for Traffic Safety</h1>
<div id="keywords" class="section level4">
<h4><span class="header-section-number">2.0.0.1</span> Keywords</h4>
<p>traffic fatalities, self-driving cars, autonomous vehicles, smart intersections, machine learning, predictive analytics</p>
</div>
<div id="smart-self-sensing-intersections-could-save-lives" class="section level2">
<h2><span class="header-section-number">2.1</span> Smart, Self-Sensing Intersections Could Save Lives</h2>
<p>According to the <a href="http://asirt.org/initiatives/informing-road-users/road-safety-facts/road-crash-statistics">Association for Safe International Road Travel</a>, thousands of lives are lost worldwide <em>each day</em> when cars collide with each other and with other roadway users, such as motorcyclists, pedestrians, cyclists, etc. Such collisions also lead to tens of millions of injuries each year, causing untold pain and productivity loss. Many count on the advent of self-driving cars to fix the problem for good, yet it could very well be decades before even a single country’s fleet is fully automated. Let’s not wait on that solution.</p>
<div class="figure" style="text-align: center"><span id="fig:descanso"></span>
<img src="img/Colorado_family_visits_intersection_memorial.jpg" alt="Colorado family visits roadside memorial. [@riley_family_2017]" width="100%" />
<p class="caption">
Figure 2.1: Colorado family visits roadside memorial. <span class="citation">(<span class="citeproc-not-found" data-reference-id="riley_family_2017"><strong>???</strong></span>)</span>
</p>
</div>
<p>About 40% of crashes take place at intersections <span class="citation">(Choi <a href="#ref-choi_crash_2010">2010</a>)</span>, and it has been determined that over 50% of those intersection crashes are due to either “inadequate intersection surveillance” or “turning into an intersection with an obstructed view”. Traffic signals and stop signs can only <em>prompt</em> users to follow the rules of the road, they can’t force compliance. All roadway users cheat the rules when in a rush, knowing that lights (and certainly signs) don’t have realtime information like their own senses (supposedly) do. But humans are lousy at surveillance; there are blind spots in what we can see (behind utility poles, trees, tall vehicles, curves, etc.) and there are also blind spots in what we recognize (if you’re not looking for a bike, you may not see one). The tragedy lies in thinking you’ve adequately scanned your surroundings, when in fact you haven’t. Such a lack of information on-hand (right in the very moment a critical decision is being made) seems like something that we in the so-called <em>information age</em> should be able to address.</p>
<p>This project aims to partner with one of the cities that has already committed to the <a href="https://visionzeronetwork.org/resources/vision-zero-cities/">Vision Zero Network</a>, with the aim of investigating whether an inexpensive new Data Science approach could help prevent traffic fatalities and serious injuries at known-dangerous intersections. Researchers have analyzed years of data regarding such intersections where - time and time again - people and property are harmed, reports are written, debris is cleared away, and then traffic flow continues…until the next crash <span class="citation">(Chen, Cao, and Logan <a href="#ref-chen_analysis_2012">2012</a>)</span>. Everything gets scrutinized, down to crosswalk wait times and headphone use <span class="citation">(Brosseau et al. <a href="#ref-brosseau_impact_2013">2013</a>)</span>. It’s encouraging that <em>informing</em> pedestrians with a countdown showing how long they’ll have to wait (given present signal timings) can reduce illegal jaywalking<span class="citation">(<span class="citeproc-not-found" data-reference-id="lipovac_influence_2013"><strong>???</strong></span>)</span>. But few seem to be making plans to bridge the main information gap directly (given current users traveling via their specific methods, exactly what resource contention may be predicted for the N strips of asphalt, concrete, gravel, or dirt in this intersection).</p>
<p>What if, instead of waiting for a slowly-growing number of smart cars to learn to handle every possible intersection and/or roadway condition, we instead invested in instrumenting known-bad intersections, turning them into informed, connected objects, with knowledge of their own historical pitfalls? We can invest in the infrastructure we already have a lot more easily than we can goad drivers into purchasing fancy new smart cars. We can teach smart intersections to track their users, learn their trajectory patterns by user type, and inform those present whenever a collision is probable. And when we fail, smart intersections can instantly notify emergency responders, and warn off incoming users.</p>
<p>Some municipalities are already installing cameras at intersections in order to use computer vision to detect, classify and warn of potential conflicts <span class="citation">(Zangenehpour, Miranda-Moreno, and Saunier <a href="#ref-zangenehpour_automated_2015">2015</a>)</span>. This work with video is challenging, however, “due to the constant change of orientation and appearance of pedestrians and cyclists”. It’s very likely that certain maneuvers (like an illegal U-turn) may be best detected with cameras, but cameras also require clear sight-lines and must transmit and store a vast amount of data. The following approach could certainly work alongside cameras in intersections that warrant the highest level of instrumentation, but for the vast majority of intersections that won’t get video surveillance any time soon, the following proposal recommends another path, relying on road user characteristics that don’t change as often as visuals, and also preventing the transmission and storage of personally-identifiable information.</p>
</div>
<div id="the-data-science-of-smart-intersections" class="section level2">
<h2><span class="header-section-number">2.2</span> The Data Science of Smart Intersections</h2>
<p>The key to this project’s approach lies in the classification and characterization of roadway users according to mass (which, unlike physical appearance/orientation, does <em>not</em> change during traversal of a given intersection) and velocity (which can be expected to change only within predictable user-type bounds). The combination of mass and velocity is momentum - literally defined as mass in motion. Momentum is an especially appropriate factor for classification and prediction in a traffic risk-avoidance scenario because momentum is conserved in a collision: the wider the gap between two objects’ momentums, the more potential harm to the lower-momentum party. Given like speeds, a wheelchair user hitting someone on a bike will do much less harm than an 18-wheeler hitting someone on a bike.</p>
<p>For this pilot project, snapshots of momentum would be determined for each roadway user approaching an intersection via means of a <em>series</em> of inexpensive, weather-proof vibration-sensor packs, semi-permanently adhered to intersection surfaces (like curbing). Each individual sensor-pack would be a combination of <a href="https://www.adafruit.com/product/1739">piezoelectric elements</a> - converting various levels of vibration into various levels of voltage - and an array of <a href="https://www.adafruit.com/?q=vibration%20sensor%20switch">vibration sensor switches</a> - which either do or do not close a circuit, depending on the level of vibration impinging upon them. While pilot placement is envisioned along the vertical edges of curbing walls, it is not inconceivable that (in the absence of curbing) such components could be installed in ordinary roadway reflectors in a later phase, expanding coverage to more of the population. Additionally, some intersections already have car-counting strips, and a series of these on approach routes could augment sensor-packs that must be installed further from roadways in order not to miss users without vehicles.</p>
<p>An intersection’s set of sensor-packs should be distributed every few meters along its approach paths (for instance, along each of 3 lanes in a “T”-shaped intersection). BLE (Bluetooth low energy) wireless connections would communicate precise sensor-pack locations and vibration readings - all in real-time - to the smart intersection’s own edge gateway device. It is important to note that we must avoid network latency in this situation where milliseconds can matter. The gateway device must be capable of performing the real-time analysis and alerting onsite, forwarding only compressed, aggregate data to the internet for tasks that can lag, like monitoring and maintenance.</p>
<p>Once a pilot intersection’s gateway is set up to receive data from its sensor-packs, the Data Science team will supervise training of its software, so that this individual intersection can classify its intersection users according to user types, identifying, for instance:</p>
<ul>
<li>a deer 🦌 vs.</li>
<li>a child on a scooter 🛴 vs.</li>
<li>a wheelchair user ♿ vs.</li>
<li>a bike commuter 🚴♀️ vs.</li>
<li>a giant delivery truck 🚚, etc.</li>
</ul>
<p>One key point is that training of the machine learning models must be an investment in each intersection (and its sensor pack installations) individually. There’s no other adequate way to establish ground truth to the level of precision our predictions would require. A given piece of concrete may produce certain vibrations when traversed by a wheelchair, and an altogether different pattern may emerge from a standard skateboard. Similarly, a speed bump comprised of a given material could get walloped by a racing fire engine one moment (producing large vibrations) and then barely move the needle moments later when crossed by a thin-wheeled roadbike. All of this could likely be measured during normal traffic flow, or else detoured-&amp;-artificially-controlled traffic flow. Community input and intersection-specific historical incident data can be used as well. For instance, a gravel bike path leading to a busy crossing to an elementary school may need specialty sensors or additional training. Prior to “going live” with any given smart intersection, transportation safety staff would be involved to conduct a gauge repeatability and reproducibility study, logging the intersection’s new instrumented capabilities and/or any areas that may need improvement.</p>
<p>Why does classification of user type and momentum matter so much? Two reasons: 1. We expect that segmenting user types will improve the predictability of user trajectories, because standard deviations by type are likely to have a much tighter sigma (vs lumping all roadway users into one probability distribution). You will rarely see a baby carriage dart in front of a speeding truck, but deer often exhibit this very behavior. Trains rarely make sudden U-turns, but cars just might (especially when seeing their way blocked by a long train). 2. We should also aim on the side of caution when predicting collision risk if/when more vulnerable roadway users are present. Sideswiping a truck isn’t as dangerous as sideswiping a trike. Our tolerances can and should be tighter. Many states have laws about stopping all traffic flow adjacent to offloading school buses. Can you think of an intersection that frequently sees big disparities in user momentum? One that often has real-time signals and even access controls? Think about where you’re 40x more likely to die than if you were hit by a car - a railroad crossing <span class="citation">(<span class="citeproc-not-found" data-reference-id="dot_railroad_nodate"><strong>???</strong></span>)</span>. The train’s momentum is so high that it’s hard to wrap a human brain around (e.g. it can take over a mile for a train to reach a complete stop).</p>
<p>Once live, an intersection’s status (for instance, 2 cyclists approaching uphill, a delivery van barreling downhill, and a wheelchair user waiting behind a utility pole to enter the crosswalk) could be broadcast locally to a “See Around Corners” mobile app. Those wishing to make informed intersection traversals could simply download the app and activate voice warnings, hearing “Incoming downhill!” in any preferred language. Notice especially that anyone - not just drivers - could avail themselves of this foresight. Perhaps, with the backing of Vision Zero and a large metro area, car manufacturers could be persuaded to incorporate smart intersection data into their auto-braking technology. Regulations could force older commercial vehicles without such tech to install positive control mechanisms, or at least require verbal warnings for drivers. And cities seeking faster progress on their Vision Zero goals could install sight/sound devices at every corner of a problematic intersection, enabling “in-your-face” warnings from our intersection “guardian angels”…at least until we develop instant force-fields.</p>
<p>The fundamental research question then becomes: can machine learning be used to train a smart intersection to detect and classify roadway users, predicting potential paths with enough precision to warn users <em>before</em> a collision? If so, what level of false positives and false negatives should be expected and accepted? What degradation in a given intersection’s sensor or prediction service levels should trigger remediation? This would be a topic of debate, surely, but with the backing of experts at the Vision Zero Network, we imagine that stakeholders like city governments, emergency responders, auto insurers, and parents could push for adoption of minimum levels of protection. While it took time, this same coalition was successful in fighting the status quo and establishing cutoffs regarding blood alcohol levels allowed while driving - some of which are even enforced down to an individual driver’s starter-interrupter device.</p>
</div>
<div id="self-driving-cars-to-co-exist-with-smart-intersections" class="section level2">
<h2><span class="header-section-number">2.3</span> Self-Driving Cars to Co-Exist with Smart Intersections</h2>
<p>Autonomous cars are on the roads now <span class="citation">(Hersman and Lee <a href="#ref-hersman_reducing_2017">2017</a>)</span>, and this project takes no issue with their progress. When cars can keep other cars (and buses, and trains, etc.) informed about which resources are needed by whom and when, movements can be coordinated and accident rates should fall.</p>
<p>But mixed-mode transit is also here to stay, and therefore we can’t expect vehicles alone to carry all the burden of preventing roadway injury and death. There will always be other modes in play. Globally, some prefer not to own a vehicle, and some don’t have the means. Many embrace active modes of transportation, like walking and cycling. This shouldn’t relegate large swathes of the population to simply being a special category for accommodation in car company’s self-driving algorithms <em>if at all possible</em>. Instead, we can be designing traffic safety solutions designed to work <em>now</em>, folding in autonomous vehicles as they gain traction. Every node - including smart, self-sensing intersections - in our transit grid can contribute. It’s time we smarten up our intersections so they can serve and protect everyone.</p>
<p>🚌 - ♿ - 🏍️ - 🛹 - 🚒 - 🚶🏿 - 🛵 - 🛹 - 🏎️ - ⛹️♀️ - 🛴 - 🏃🏼 - 🧳 - 🚙 - 🚴🏽♀️ - 🚓 - 🚇</p>

</div>
</div>
<h3>Bibliography</h3>
<div id="refs" class="references">
<div id="ref-choi_crash_2010">
<p>Choi, Eun-Ha. 2010. <em>Crash Factors in Intersection-Related Crashes: An on-Scene Perspective</em>. NHTSA Technical Report. Washington, DC: U.S. Dept. of Transportation, National Highway Traffic Safety Administration.</p>
</div>
<div id="ref-chen_analysis_2012">
<p>Chen, Huiqin, Libo Cao, and David B. Logan. 2012. “Analysis of Risk Factors Affecting the Severity of Intersection Crashes by Logistic Regression.” <em>Traffic Injury Prevention</em> 13 (3): 300.</p>
</div>
<div id="ref-brosseau_impact_2013">
<p>Brosseau, Marilyne, Sohail Zangenehpour, Nicolas Saunier, and Luis Miranda-Moreno. 2013. “The Impact of Waiting Time and Other Factors on Dangerous Pedestrian Crossings and Violations at Signalized Intersections: A Case Study in Montreal.” <em>Transportation Research Part F: Psychology and Behaviour</em> 21 (November): 159–72. doi:<a href="https://doi.org/10.1016/j.trf.2013.09.010">10.1016/j.trf.2013.09.010</a>.</p>
</div>
<div id="ref-zangenehpour_automated_2015">
<p>Zangenehpour, Sohail, Luis F. Miranda-Moreno, and Nicolas Saunier. 2015. “Automated Classification Based on Video Data at Intersections with Heavy Pedestrian and Bicycle Traffic: Methodology and Application.” <em>Transportation Research Part C</em> 56 (July): 161–76. doi:<a href="https://doi.org/10.1016/j.trc.2015.04.003">10.1016/j.trc.2015.04.003</a>.</p>
</div>
<div id="ref-hersman_reducing_2017">
<p>Hersman, Deborah A.P., and John D. Lee. 2017. “Reducing Traffic Deaths: Can Automation and Tougher Laws Save Lives?” <em>CQ Researcher</em> 27 (7): 145.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="brass-knuckles-for-the-information-age.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bibliography.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/w201rdada/portfolio-jendatx/edit/master/02.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

</body>

</html>
