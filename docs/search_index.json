[
["index.html", "W201 Portfolio Welcome! About the author", " W201 Portfolio Jennifer Darrouzet MIDS Spring 2018 Welcome! Figure .: Hello World! Pariatur sapiente anim waistcoat bicycle rights. Cupidatat chambray portland direct trade, XOXO odio gochujang banjo deep v sustainable. Sint jianbing DIY humblebrag heirloom exercitation ennui fanny pack. Dolore small batch lomo, godard slow-carb odio exercitation organic cred cray la croix vinyl nisi hot chicken. Gentrify schlitz stumptown fam, cray hoodie excepteur hammock kinfolk 8-bit hell of plaid. Helvetica hashtag pinterest typewriter, tbh vape vero farm-to-table. Laboris bitters aliqua small batch. Abstract of my first cool idea Hi Iâ€™m an abstract for your first big idea! Iâ€™m also a text reference, which is a line of text you can reuse in several places. Use me to write a one paragraph abstract and place it in index.Rmd as well as under the title of 01.Rmd. Once defined, you can reuse me simply by writing (ref:abs1) where you want this text to go. Abstract of my second cool idea Vero dolor franzen letterpress. Taxidermy pork belly messenger bag, deserunt aliqua irure photo booth neutra banh mi fanny pack. Butcher fam heirloom marfa. Tilde reprehenderit snackwave tempor. Qui pop-up kitsch dolor. Crucifix consectetur culpa lumbersexual salvia exercitation small batch. Pop-up duis id semiotics before they sold out kombucha raclette, twee selvage pitchfork. (ref:abs2) About the author Sustainable aute gochujang, messenger bag vero dolor blog pork belly knausgaard. Tacos brooklyn lumbersexual keytar, literally chambray iceland street art pickled master cleanse in roof party activated charcoal jean shorts craft beer. Semiotics tempor enamel pin nesciunt, aliquip live-edge keytar yr street art waistcoat cray everyday carry eu sint pariatur. Aliquip anim godard leggings, flexitarian direct trade humblebrag. Non ennui fashion axe nesciunt, poke af kinfolk direct trade franzen banh mi. Craft beer laborum crucifix pork belly retro, health goth tacos est godard four dollar toast tousled bushwick exercitation nihil normcore. Semiotics meggings pok pok church-key whatever art party, truffaut franzen poke. Updated: 2018-02-27 "],
["brass-knuckles-for-the-information-age.html", "1 Pooook Prose Knuckles 1.1 Still Chained to our Keyboards? 1.2 Data Science to Kick the Keyboard Habit 1.3 The Post-Keyboard Era", " 1 Pooook Prose Knuckles Figure 1.1: Prototype Design 1.0.0.1 Keywords {wearables, touch type, keyboarding, knuckles} 1.1 Still Chained to our Keyboards? Picture a desk worker, stepping out for lunch - only to have his or her phone blow up with texts, messages, and emails ğŸ”¥ğŸ“±ğŸ”¥. Should this mid-day â€œbreakâ€ be spent mentally composing - and hoping to later recall - intended replies until back at a keyboard? Or face-down, inefficiently stabbing at a tiny alphabet on a tiny screen? These choices are especially painful for those of us who can touch-type with speed and accuracy. Weâ€™re the ones who type only a little slower than we think. Weâ€™re the ones who find voice recognition software especially galling: all that imprecision with key people/place/product names, punctuation and formatting requires time-consuming rework. Not to mention that dictating sensitive content requires constant access to a quiet, private place - lest we be overheard. What we want is a way to untether our typing skillsâ€¦without having to ditch years of muscle memory. There is a â€œcoming soonâ€ product called Tap that purports to offer keyboard-free gesture recognition for â€œtyping, gaming, music and more,â€ but this device requires users spend hours getting trained with uncomfortable new fingerings (â€œdâ€ is typed by pressing down with the middle and pinky fingers, while lifting the ring finger, for instance). If we wanted to learn guitar- or piano-like chord fingerings, weâ€™d pick up a musical instrument! Instead, itâ€™s time we design a wearable solution that leverages our time-tested typing skills - already standardized via QWERTY and Dvorak keyboards. With the miniature accelerometers that can translate motion into device input now at hobbyist pricepoints, we can loose the chains tying good typists to our keyboards. Thereâ€™s really no good reason why we canâ€™t compose our prose on any surface - literally - at hand. And itâ€™s not just desk workers who could benefit from board-cutting in addition to cord-cutting. Picture: the farmer ğŸ‘©ğŸ¼ ğŸŒ¾ inspecting a field, the scientist ğŸ‘¨ğŸ¾ ğŸ”¬ elbows-deep in an experiment, the investigative journalist ğŸ•µğŸ¼ chasing a quickly-developing ğŸ“° story the surgeon ğŸ‘© âš•ï¸ already prepped for surgery, the activist blogger ğŸ§•ğŸ½ attending a protest the cop ğŸ‘®ğŸ½ out walking the beat, etc. In all of the above cases, silently capturing observations (or executing just-in-time precision searches) could be invaluable. Thereâ€™s really no need for our speciesâ€™ continued reliance on the keyboard. Someday soon, keyboards are going to look about as antiquated as the punch card. 1.2 Data Science to Kick the Keyboard Habit The Pooook Prose Knuckles product concept is to embed the necessary sensor circuits into a pair of wearable input devices having the form factor of brass knuckles, but bendy like those Livestrong bracelets. The consumer owning a pair of Pooooks would pair them with a phone or tablet, and then simply parrot a few on-screen prompts to train their personalized wearables to interpret their individual typing style. The design would build on the Ring GINA wearable computer interaction devices (Greenspun and Pister 2014) developed in UC Berkeleyâ€™s Department of Electrical Engineering and Computer Science. Our data science team would design Pooook flexible knuckle-sets to be 3D printed with the end goal being to insert the necessary accelerometers, Bluetooth connectors, and wristwatch-style â€œself-windingâ€ batteries. Once we assemble the prototype devices, the data science team would recruit touch-typing testers with measurably fast and accurate keyboarding skills for the machine learning portion of the project. For each tier in the increasingly-complex standard keyboard inputs listed below, the data science team would design software to classify Pooook-sensed accelerated finger movements in x-y-z space, outputting granular values corresponding to typed input: Tier 1 letters: â€œaâ€ vs â€œqâ€ and â€œzâ€, â€œfâ€ vs â€œrâ€ and â€œvâ€, etc. Tier 2 essential punctuation: spacebar, return, delete, apostrophe, comma, periodâ€¦ Tier 3 punctuation requiring shifting (e.g. â€œ?â€, quotes, colon etc.) Tier 4 capital letters (again requiring shifting) Tier 5 numbers (both inline and via number-keypads like those used by cashiers) Tier 6 special characters (@, $, %, +, -, *, /, etc.) The â€œground truthâ€ for machine learning in each tier would always begin with keyboards under the hands of the Pooook-wearing typists, who would input expected (screen-prompted, then later improvised) characters, words, and phrases. Once accuracy is proven with keyboards in place, the keyboard hardware would be removed and replaced with solid flat surfaces (like a desk), angled flats (like an airplaneâ€™s fold-down tray), and ultimately curved &amp; softer spots like chair arms and the typistsâ€™ laps. This keyboard-first approach would be recommended to the ultimate consumers as well (whether at home or in stores/schools/libraries), so that the software can be personalized to the way each individual typist engages. To achieve snappy time-to-value for new owners of the product, the data science goal should be that Pooook customers have no need to change their typing behavior. Customers should train the Pooooks, and not the other way around. 1.3 The Post-Keyboard Era Once freed from bulky keyboards, humans can more easily get out into the world - reporting better the truth of what we find there, and what we think about these findings. Weâ€™ll procrastinate and forget less, as we wonâ€™t have to put off until later that which we can do RIGHT. NOW. All of us could benefit, too, from additional contributors. Perhaps a billion of our fellow travelers on this planet use their ğŸ“± as their only means of connection to the information age. Without full-size keyboards to make prose composition easy and efficient, some may feel relegated to the role of information accessors, not as much information creators. Itâ€™s time the internet era benefited from the voices and ideas of all of us ğŸ“ˆ. While Pooook would first be developed for the English QWERTY and Dvorak keyboards, that certainly doesnâ€™t mean Pooook software models would stop there. In fact, the Pooook data science team should aim to design an API-first platform, so that developers everywhere could extend their Pooook software to provide precise input as needed in more circumstances: international languages, math, science, and industry-specifics, accessibility tools, and more. Isnâ€™t it time for wearable precision input devices? Join the Pooook team today! Bibliography "],
["smart-intersections-could-save-lives.html", "2 See Around Corners for Traffic Safety 2.1 Smart, Self-Sensing Intersections Could Save Lives 2.2 The Data Science of Smart Intersections 2.3 Self-Driving Cars to Co-Exist with Smart Intersections", " 2 See Around Corners for Traffic Safety 2.0.0.1 Keywords {traffic fatalities, self-driving cars, autonomous vehicles, smart intersections} 2.1 Smart, Self-Sensing Intersections Could Save Lives According to the Association for Safe International Road Travel, thousands of lives are lost worldwide each day when cars collide with each other and with other roadway users, such as motorcyclists, pedestrians, cyclists, etc. Such collisions also lead to tens of millions of injuries each year, causing untold pain and productivity loss. Many count on the advent of self-driving cars to fix the problem for good, yet it could very well be decades before even a single countryâ€™s fleet is fully automated. Letâ€™s not wait on that solution. About 40% of crashes take place at intersections (Choi 2010), and it has been determined that over 50% of those intersection crashes are due to either â€œinadequate intersection surveillanceâ€ or â€œturning into an intersection with an obstructed viewâ€. These causes point directly to a lack of information on-hand in the moment a critical decision is being made - something that we in the so-called information age should be able to address. Researchers have analyzed years of data regarding dangerous intersections where - time and time again - people and property are harmed, reports are written, debris is cleared away, and then traffic flow continuesâ€¦until the next crash (Chen, Cao, and Logan 2012). Everything gets scrutinized, down to crosswalk wait times and headphone use (Brosseau et al. 2013) and even gender differences in car-bicycle crashes at urban intersections (Stipancic et al. 2016). But few are making plans to bridge the main information gap directly: what resource contention might be predicted for the same strip of asphalt, concrete, gravel, or dirt. What if, instead of waiting for a slowly-growing number of smart cars to learn to handle every possible roadway condition plus every possible style of intersection, we instead invested in instrumenting known-bad intersections, turning them into informed, connected objects, with knowledge of their own historical pitfalls? What if they could become proactive, monitoring themselves and their users, preventing accidents, and even notifying emergency responders if needed. Figure 2.1: Enter this obstructed, sloped, and curving intersection at your peril There are a few investigating this approach, installing cameras at intersections in order to use computer vision to detect, classify and warn of potential conflicts (Zangenehpour, Miranda-Moreno, and Saunier 2015). This work with video is challenging, however, â€œdue to the constant change of orientation and appearance of pedestrians and cyclistsâ€. The following proposal recommends another path, relying on less variable characteristics. After all, the objective is to find a solution that is inexpensive and effective enough to install widely - protecting the most people possible. 2.2 The Data Science of Smart Intersections The key to this projectâ€™s approach lies in the classification and characterization of roadway users according to mass (which, unlike physical appearance/orientation, does not change during traversal of a given intersection) and velocity (which can be expected to change only within predictable user-category bounds). The combination of mass and velocity is momentum - literally defined as mass in motion. Momentum is an especially appropriate factor for classification and prediction in a traffic risk-avoidance scenario because momentum is conserved in a collision: the wider the gap between two objectsâ€™ momentums, the more potential harm to the lower-momentum party. For this pilot project, snapshots of momentum would be determined for each roadway user approaching an intersection via means of a series of inexpensive, weather-proof vibration-sensor packs, semi-permanently adhered to intersection surfaces (like curbing). Each individual sensor-pack would be a combination of piezoelectric elements - converting various levels of vibration into various levels of voltage - and an array of vibration sensor switches - which either do or do not close a circuit, depending on the level of vibration impinging upon them. While pilot placement is envisioned along the vertical edges of curbing walls, it is not inconceivable that (in the absence of curbing) such components could be installed in ordinary roadway reflectors, expanding coverage to more of the population. An intersectionâ€™s set of sensor-packs should be distributed every few meters along intersection approach paths (for instance, along each of 3 lanes in a â€œTâ€-shaped intersection). Wirelessly connections would communicate precise sensor-pack locations and vibration readings - all in real-time - to the smart intersectionâ€™s own network hub. This hub would itself be connected to the internet for monitoring, maintenance, and in case of emergency reporting, but note that no personally-identifiable information need be transmitted to the intersectionâ€™s hub (unlike with cameras). Once a pilot intersection is set up to receive data from its sensor-packs, the Data Science team will supervise training of its software, so that the intersection can classify intersection users according to risk categories, identifying, for instance: a deer ğŸ¦Œ vs. a child on a scooter ğŸ›´ vs. a wheelchair user â™¿ vs. a bike commuter ğŸš´â™€ï¸ vs. a giant delivery truck ğŸšš, etc. Ground truth for any given intersection could be measured during normal or detoured-&amp;-artificially-controlled traffic flow. Community input and intersection-specific historical performance data can be used as well; for instance, a crossing near a school for the blind could include special tuning. Prior to â€œgoing liveâ€ with any given smart intersection, transportation safety staff could conduct a gauge repeatability and reproducibility study, logging the intersectionâ€™s new instrumented capabilities and/or any areas that may need improvement. Once live, an intersectionâ€™s status (for instance, 2 cyclists approaching uphill, a delivery van barreling downhill, and a wheelchair user waiting behind a utility pole to enter the crosswalk) could be broadcast locally to a â€œSee Around Cornersâ€ mobile app. Those wishing to make informed intersection traversals could simply download the app and activate voice warnings, hearing â€œIncoming downhill!â€ in any preferred language. Notice especially that anyone - not just drivers - could avail themselves of this foresight. The fundamental research question then becomes: can machine learning be used to train a smart intersection to detect and classify roadway users, predicting potential paths with enough precision to warn users before a collision? If so, what level of false positives and false negatives should be expected and accepted? And then, what are the incentives that stakeholders - like local governments, parents, or insurers - can offer in order to encourage the public to tune into what smart intersections have to say? 2.3 Self-Driving Cars to Co-Exist with Smart Intersections Autonomous cars are on the roads now (Hersman and Lee 2017), and this project takes no issue with their progress. When cars can keep other cars (and buses, and trains, etc.) informed about which resources are needed by whom and when, movements can be coordinated and accident rates should fall. But mixed-mode transit is also here to stay, and therefore we canâ€™t expect vehicles alone to carry all the burden of preventing roadway injury and death. There will always be other modes in play. Globally, some prefer not to own a vehicle, and some donâ€™t have the means. Many embrace active modes of transportation, like walking and cycling. This shouldnâ€™t relegate large swathes of the population to simply being labelled as â€œvulnerable roadway usersâ€ (H Naci 2009) to accommodate in a car companyâ€™s self-driving algorithm, if at all possible. Instead, we can be designing traffic safety solutions designed to fold in (but not rely only upon) autonomous vehicles. Every node - including smart, self-sensing intersections - in our transit grid can contribute. Itâ€™s time we smarten up our intersections so they can serve and protect everyone. ğŸšŒ - â™¿ - ğŸï¸ - ğŸ›¹ - ğŸš’ - ğŸš¶ğŸ¿ - ğŸ›µ - ğŸ›¹ - ğŸï¸ - â›¹ï¸â™€ï¸ - ğŸ›´ - ğŸƒğŸ¼ - ğŸ§³ - ğŸš™ - ğŸš´ğŸ½â™€ï¸ - ğŸš“ - ğŸš‡ Bibliography "],
["bibliography.html", "Bibliography", " Bibliography "]
]
